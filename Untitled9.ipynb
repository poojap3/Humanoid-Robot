{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c08e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "def auto_canny(image, sigma=0.33):\n",
    "    '''\n",
    "    This function automatically detects the edges of an input image.\n",
    "    reference:https://www.pyimagesearch.com/2015/04/06/zero-parameter-automatic-canny-edge-detection-with-          \n",
    "    python-and-opencv/\n",
    "    '''\n",
    "    # compute the median of the single channel pixel intensities\n",
    "    v = np.median(image)\n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    edged = cv2.Canny(image, lower, upper)\n",
    "    # return the edged image\n",
    "    return edged\n",
    "image = cv2.imread('app.png')\n",
    "image_d = image.copy()\n",
    "img_blur = cv2.GaussianBlur(image, (5,5), 0)\n",
    "img_ms = cv2.pyrMeanShiftFiltering(img_blur, 10, 90)\n",
    "\n",
    "edge = auto_canny(img_ms)\n",
    "cnts,_ = cv2.findContours(edge.copy(), cv2.RETR_EXTERNAL,\n",
    "        cv2.CHAIN_APPROX_SIMPLE)\n",
    "c_num=0\n",
    "for i,c in enumerate(cnts):\n",
    "    # draw a circle enclosing the object\n",
    "    ((x, y), r) = cv2.minEnclosingCircle(c)\n",
    "    if r>34:\n",
    "        c_num+=1\n",
    "        cv2.circle(image_d, (int(x), int(y)), int(r), (0, 255, 0), 2)\n",
    "        cv2.putText(image_d, \"#{}\".format(c_num), (int(x) - 10, int(y)), \n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "cv2.imshow(\"Image with Apples\",image)\n",
    "cv2.imshow(\"Edge Map\", edge)\n",
    "cv2.imshow(\"Image with detected Apples\",image_d)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe88c7c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xe but this version of numpy is 0xd",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0xe but this version of numpy is 0xd"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xe but this version of numpy is 0xd",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0xe but this version of numpy is 0xd"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xe but this version of numpy is 0xd",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0xe but this version of numpy is 0xd"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "initialization of _pywrap_checkpoint_reader raised unreported exception",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16004/1836661211.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcvlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcvlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_detection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdraw_bbox\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'app.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\cvlib\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mface_detection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdetect_face\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mobject_detection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdetect_common_objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mgender_detection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdetect_gender\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_frames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manimate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\cvlib\\gender_detection.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0minitialize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m# Bring in subpackages.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m# from tensorflow.python import keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mservice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdense_to_ragged_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdense_to_sparse_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    385\u001b[0m \"\"\"\n\u001b[0;32m    386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfrom_dataset_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregister_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_server_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptions_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstructured_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgraph_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptions_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstructured_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtype_spec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgen_dataset_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseSaverBuilder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtracking\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_saved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheckpoint_management\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpy_checkpoint_reader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msaveable_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pywrap_checkpoint_reader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCheckpointReader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_export\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf_export\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: initialization of _pywrap_checkpoint_reader raised unreported exception"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import cvlib as cv\n",
    "from cvlib.object_detection import draw_bbox\n",
    "im = cv2.imread('app.png')\n",
    "bbox, label, conf = cv.detect_common_objects(im)\n",
    "output_image = draw_bbox(im, bbox, label, conf)\n",
    "plt.imshow(output_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba160b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cvlib\n",
      "  Downloading cvlib-0.2.7.tar.gz (13.1 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\anaconda3\\lib\\site-packages (from cvlib) (1.19.5)\n",
      "Collecting progressbar\n",
      "  Downloading progressbar-2.5.tar.gz (10 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\lib\\site-packages (from cvlib) (2.27.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\asus\\anaconda3\\lib\\site-packages (from cvlib) (9.0.1)\n",
      "Requirement already satisfied: imageio in c:\\users\\asus\\anaconda3\\lib\\site-packages (from cvlib) (2.9.0)\n",
      "Requirement already satisfied: imutils in c:\\users\\asus\\anaconda3\\lib\\site-packages (from cvlib) (0.5.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->cvlib) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->cvlib) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->cvlib) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->cvlib) (2.0.4)\n",
      "Building wheels for collected packages: cvlib, progressbar\n",
      "  Building wheel for cvlib (setup.py): started\n",
      "  Building wheel for cvlib (setup.py): finished with status 'done'\n",
      "  Created wheel for cvlib: filename=cvlib-0.2.7-py3-none-any.whl size=10046386 sha256=0dbe7243bf67abb8e0fbe2a3b1d743c8053019ef3f53fa3d74e7a7363fbb50b6\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\96\\ad\\4c\\d80d4bf4143c154ab297e2384915c89aff43d77d1787b9a702\n",
      "  Building wheel for progressbar (setup.py): started\n",
      "  Building wheel for progressbar (setup.py): finished with status 'done'\n",
      "  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12082 sha256=912fdacfe25b27ad98bbc039756a5424d1b825e7192ffe7368ffc69a4346c9a4\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\d7\\d9\\89\\a3f31c76ff6d51dc3b1575628f59afe59e4ceae3f2748cd7ad\n",
      "Successfully built cvlib progressbar\n",
      "Installing collected packages: progressbar, cvlib\n",
      "Successfully installed cvlib-0.2.7 progressbar-2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cvlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c09763ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "\n",
    "\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "cap = cv2.VideoCapture('video_2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Reading the video stream\n",
    "    ret, image = cap.read()\n",
    "#                 if ret:\n",
    "#                     image = imutils.resize(image,\n",
    "#                                         width=min(400, image.shape[1]))\n",
    "\n",
    "#                     # Detecting all the regions\n",
    "#                     # in the Image that has a\n",
    "#                     # pedestrians inside it\n",
    "#                     (regions, _) = hog.detectMultiScale(image,\n",
    "#                                                         winStride=(16, 16),\n",
    "#                                                         padding=(8, 8),\n",
    "#                                                         scale=1.02)\n",
    "\n",
    "#                     # Drawing the regions in the\n",
    "#                     # Image\n",
    "#                     for (x, y, w, h) in regions:\n",
    "#                         cv2.rectangle(image, (x, y),\n",
    "#                                     (x + w, y + h),\n",
    "#                                     (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "# Start a while loop\n",
    "\n",
    "\n",
    "    # Reading the video from the\n",
    "    # webcam in image frames\n",
    "#     _, imageFrame = webcam.read()\n",
    "\n",
    "    # Convert the imageFrame in\n",
    "    # BGR(RGB color space) to\n",
    "    # HSV(hue-saturation-value)\n",
    "    # color space\n",
    "    hsvFrame = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Set range for red color and\n",
    "#                 # define mask\n",
    "#                 red_lower = np.array([136, 87, 111], np.uint8)\n",
    "#                 red_upper = np.array([180, 255, 255], np.uint8)\n",
    "#                 red_mask = cv2.inRange(hsvFrame, red_lower, red_upper)\n",
    "\n",
    "\n",
    "    green_lower = np.array([25, 52, 72], np.uint8)\n",
    "    green_upper = np.array([102, 255, 255], np.uint8)\n",
    "    green_mask = cv2.inRange(hsvFrame, green_lower, green_upper)\n",
    "\n",
    "    # Set range for blue color and\n",
    "#                 # define mask\n",
    "#                 blue_lower = np.array([94, 80, 2], np.uint8)\n",
    "#                 blue_upper = np.array([120, 255, 255], np.uint8)\n",
    "#                 blue_mask = cv2.inRange(hsvFrame, blue_lower, blue_upper)\n",
    "\n",
    "    # Morphological Transform, Dilation\n",
    "    # for each color and bitwise_and operator\n",
    "    # between imageFrame and mask determines\n",
    "    # to detect only that particular color\n",
    "    kernal = np.ones((5, 5), \"uint8\")\n",
    "\n",
    "#                 # For red color\n",
    "#                 red_mask = cv2.dilate(red_mask, kernal)\n",
    "#                 res_red = cv2.bitwise_and(img, img,\n",
    "#                                         mask = red_mask)\n",
    "\n",
    "    # For green color\n",
    "    green_mask = cv2.dilate(green_mask, kernal)\n",
    "    res_green = cv2.bitwise_and(image, image,\n",
    "                                mask = green_mask)\n",
    "\n",
    "#                 # For blue color\n",
    "#                 blue_mask = cv2.dilate(blue_mask, kernal)\n",
    "#                 res_blue = cv2.bitwise_and(img, img,\n",
    "#                                         mask = blue_mask)\n",
    "\n",
    "#                 # Creating contour to track red color\n",
    "#                 contours, hierarchy = cv2.findContours(red_mask,\n",
    "#                                                     cv2.RETR_TREE,\n",
    "#                                                     cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#                 for pic, contour in enumerate(contours):\n",
    "#                     area = cv2.contourArea(contour)\n",
    "#                     if(area > 300):\n",
    "#                         x, y, w, h = cv2.boundingRect(contour)\n",
    "#                         img = cv2.rectangle(img, (x, y),\n",
    "#                                                 (x + w, y + h),\n",
    "#                                                 (0, 0, 255), 2)\n",
    "\n",
    "#                         cv2.putText(img, \"Red Colour\", (x, y),\n",
    "#                                     cv2.FONT_HERSHEY_SIMPLEX, 1.0,\n",
    "#                                     (0, 0, 255))\t\n",
    "\n",
    "    # Creating contour to track green color\n",
    "    contours, hierarchy = cv2.findContours(green_mask,\n",
    "                                        cv2.RETR_TREE,\n",
    "                                        cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for pic, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "#                     hog = cv2.HOGDescriptor()\n",
    "#                     hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "#                     cap = cv2.VideoCapture(0)\n",
    "\n",
    "#                     while cap.isOpened():\n",
    "#                         # Reading the video stream\n",
    "#                         ret, image = cap.read()\n",
    "        if ret:\n",
    "            image = imutils.resize(image,width=min(400, image.shape[1]))\n",
    "\n",
    "            # Detecting all the regions\n",
    "            # in the Image that has a\n",
    "            # pedestrians inside it\n",
    "            (regions, _) = hog.detectMultiScale(image,\n",
    "                                                winStride=(16, 16),\n",
    "                                                padding=(8, 8),\n",
    "                                                scale=1.02)\n",
    "\n",
    "            # Drawing the regions in the\n",
    "            # Image\n",
    "            for (x, y, w, h) in regions:\n",
    "                cv2.rectangle(image, (x, y),\n",
    "                            (x + w, y + h),\n",
    "                            (0, 0, 255), 2)\n",
    "\n",
    "        if(area > 300):\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            img = cv2.rectangle(image, (x, y),\n",
    "                                    (x + w, y + h),\n",
    "                                    (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "            (regions, _) = hog.detectMultiScale(img,\n",
    "                            winStride=(16, 16),\n",
    "                            padding=(8, 8),\n",
    "                            scale=1.02)\n",
    "\n",
    "        # Drawing the regions in the\n",
    "        # Image\n",
    "            for (x, y, w, h) in regions:\n",
    "                cv2.rectangle(image, (x, y),\n",
    "                            (x + w, y + h),\n",
    "                            (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "\n",
    "            cv2.putText(img, \"Green Colour\", (x, y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1.0, (0, 255, 0))\n",
    "\n",
    "#                 # Creating contour to track blue color\n",
    "#                 contours, hierarchy = cv2.findContours(blue_mask,\n",
    "#                                                     cv2.RETR_TREE,\n",
    "#                                                     cv2.CHAIN_APPROX_SIMPLE)\n",
    "#                 for pic, contour in enumerate(contours):\n",
    "#                     area = cv2.contourArea(contour)\n",
    "#                     if(area > 300):\n",
    "#                         x, y, w, h = cv2.boundingRect(contour)\n",
    "#                         img = cv2.rectangle(img, (x, y),\n",
    "#                                                 (x + w, y + h),\n",
    "#                                                 (255, 0, 0), 2)\n",
    "\n",
    "#                         cv2.putText(img, \"Blue Colour\", (x, y),\n",
    "#                                     cv2.FONT_HERSHEY_SIMPLEX,\n",
    "#                                     1.0, (255, 0, 0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    cv2.imshow('img', image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break    \n",
    "# Release the VideoCapture object\n",
    "cap.release()\n",
    "# video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f0028e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (Temp/ipykernel_8048/4252338842.py, line 93)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\ASUS\\AppData\\Local\\Temp/ipykernel_8048/4252338842.py\"\u001b[1;36m, line \u001b[1;32m93\u001b[0m\n\u001b[1;33m    image = imutils.resize(image,\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "cap = cv2.VideoCapture('video_2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Reading the video stream\n",
    "    ret, image = cap.read()\n",
    "    if ret:\n",
    "        image = imutils.resize(image,\n",
    "                            width=min(400, image.shape[1]))\n",
    "\n",
    "        # Detecting all the regions\n",
    "        # in the Image that has a\n",
    "        # pedestrians inside it\n",
    "        (regions, _) = hog.detectMultiScale(image,\n",
    "                                            winStride=(16, 16),\n",
    "                                            padding=(8, 8),\n",
    "                                            scale=1.02)\n",
    "\n",
    "        # Drawing the regions in the\n",
    "        # Image\n",
    "        for (x, y, w, h) in regions:\n",
    "            cv2.rectangle(image, (x, y),\n",
    "                        (x + w, y + h),\n",
    "                        (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "\n",
    "# Start a while loop\n",
    "\n",
    "\n",
    "    # Reading the video from the\n",
    "    # webcam in image frames\n",
    "#     _, imageFrame = webcam.read()\n",
    "\n",
    "    # Convert the imageFrame in\n",
    "    # BGR(RGB color space) to\n",
    "    # HSV(hue-saturation-value)\n",
    "    # color space\n",
    "    hsvFrame = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Set range for red color and\n",
    "    # define mask\n",
    "    red_lower = np.array([136, 87, 111], np.uint8)\n",
    "    red_upper = np.array([180, 255, 255], np.uint8)\n",
    "    red_mask = cv2.inRange(hsvFrame, red_lower, red_upper)\n",
    "\n",
    "\n",
    "#                 green_lower = np.array([25, 52, 72], np.uint8)\n",
    "#                 green_upper = np.array([102, 255, 255], np.uint8)\n",
    "#                 green_mask = cv2.inRange(hsvFrame, green_lower, green_upper)\n",
    "\n",
    "    # Set range for blue color and\n",
    "#                 # define mask\n",
    "#                 blue_lower = np.array([94, 80, 2], np.uint8)\n",
    "#                 blue_upper = np.array([120, 255, 255], np.uint8)\n",
    "#                 blue_mask = cv2.inRange(hsvFrame, blue_lower, blue_upper)\n",
    "\n",
    "    # Morphological Transform, Dilation\n",
    "    # for each color and bitwise_and operator\n",
    "    # between imageFrame and mask determines\n",
    "    # to detect only that particular color\n",
    "    kernal = np.ones((5, 5), \"uint8\")\n",
    "\n",
    "    # For red color\n",
    "    red_mask = cv2.dilate(red_mask, kernal)\n",
    "    res_red = cv2.bitwise_and(image, image,\n",
    "                            mask = red_mask)\n",
    "\n",
    "#                 # For green color\n",
    "#                 green_mask = cv2.dilate(green_mask, kernal)\n",
    "#                 res_green = cv2.bitwise_and(img, img,\n",
    "#                                             mask = green_mask)\n",
    "\n",
    "#                 # For blue color\n",
    "#                 blue_mask = cv2.dilate(blue_mask, kernal)\n",
    "#                 res_blue = cv2.bitwise_and(img, img,\n",
    "#                                         mask = blue_mask)\n",
    "\n",
    "    # Creating contour to track red color\n",
    "    contours, hierarchy = cv2.findContours(red_mask,\n",
    "                                        cv2.RETR_TREE,\n",
    "                                        cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for pic, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "        if ret:\n",
    "        image = imutils.resize(image,\n",
    "                            width=min(400, image.shape[1]))\n",
    "\n",
    "        # Detecting all the regions\n",
    "        # in the Image that has a\n",
    "        # pedestrians inside it\n",
    "        (regions, _) = hog.detectMultiScale(image,\n",
    "                                            winStride=(16, 16),\n",
    "                                            padding=(8, 8),\n",
    "                                            scale=1.02)\n",
    "\n",
    "        # Drawing the regions in the\n",
    "        # Image\n",
    "        for (x, y, w, h) in regions:\n",
    "            cv2.rectangle(image, (x, y),\n",
    "                        (x + w, y + h),\n",
    "                        (0, 0, 255), 2)\n",
    "        if(area > 300):\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            img = cv2.rectangle(image, (x, y),\n",
    "                                    (x + w, y + h),\n",
    "                                    (0, 0, 255), 2)\n",
    "\n",
    "            (regions, _) = hog.detectMultiScale(img,\n",
    "                            winStride=(16, 16),\n",
    "                            padding=(8, 8),\n",
    "                            scale=1.02)\n",
    "\n",
    "        # Drawing the regions in the\n",
    "        # Image\n",
    "            for (x, y, w, h) in regions:\n",
    "                cv2.rectangle(image, (x, y),\n",
    "                            (x + w, y + h),\n",
    "                            (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "\n",
    "            cv2.putText(img, \"Red Colour\", (x, y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.0,\n",
    "                        (0, 0, 255))\n",
    "\n",
    "\n",
    "#                 # Creating contour to track green color\n",
    "#                 contours, hierarchy = cv2.findContours(green_mask,\n",
    "#                                                     cv2.RETR_TREE,\n",
    "#                                                     cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#                 for pic, contour in enumerate(contours):\n",
    "#                     area = cv2.contourArea(contour)\n",
    "#                     if(area > 300):\n",
    "#                         x, y, w, h = cv2.boundingRect(contour)\n",
    "#                         img = cv2.rectangle(img, (x, y),\n",
    "#                                                 (x + w, y + h),\n",
    "#                                                 (0, 255, 0), 2)\n",
    "\n",
    "#                         cv2.putText(img, \"Green Colour\", (x, y),\n",
    "#                                     cv2.FONT_HERSHEY_SIMPLEX,\n",
    "#                                     1.0, (0, 255, 0))\n",
    "\n",
    "#                 # Creating contour to track blue color\n",
    "#                 contours, hierarchy = cv2.findContours(blue_mask,\n",
    "#                                                     cv2.RETR_TREE,\n",
    "#                                                     cv2.CHAIN_APPROX_SIMPLE)\n",
    "#                 for pic, contour in enumerate(contours):\n",
    "#                     area = cv2.contourArea(contour)\n",
    "#                     if(area > 300):\n",
    "#                         x, y, w, h = cv2.boundingRect(contour)\n",
    "#                         img = cv2.rectangle(img, (x, y),\n",
    "#                                                 (x + w, y + h),\n",
    "#                                                 (255, 0, 0), 2)\n",
    "\n",
    "#                         cv2.putText(img, \"Blue Colour\", (x, y),\n",
    "#                                     cv2.FONT_HERSHEY_SIMPLEX,\n",
    "#                                     1.0, (255, 0, 0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    cv2.imshow('img', image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break    \n",
    "# Release the VideoCapture object\n",
    "cap.release()\n",
    "# video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573de073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83e425a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\arithm.cpp:230: error: (-215:Assertion failed) (mtype == CV_8U || mtype == CV_8S) && _mask.sameSize(*psrc1) in function 'cv::binary_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19968/3605926376.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;31m#                 # For blue color\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0mblue_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdilate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblue_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m     res_blue = cv2.bitwise_and(img, img,\n\u001b[0m\u001b[0;32m     83\u001b[0m                                         mask = blue_mask)\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\arithm.cpp:230: error: (-215:Assertion failed) (mtype == CV_8U || mtype == CV_8S) && _mask.sameSize(*psrc1) in function 'cv::binary_op'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "cap = cv2.VideoCapture('video_2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Reading the video stream\n",
    "    ret, image = cap.read()\n",
    "    if ret:\n",
    "        image = imutils.resize(image,\n",
    "                            width=min(400, image.shape[1]))\n",
    "\n",
    "        # Detecting all the regions\n",
    "        # in the Image that has a\n",
    "        # pedestrians inside it\n",
    "        (regions, _) = hog.detectMultiScale(image,\n",
    "                                            winStride=(16, 16),\n",
    "                                            padding=(8, 8),\n",
    "                                            scale=1.02)\n",
    "\n",
    "        # Drawing the regions in the\n",
    "        # Image\n",
    "        for (x, y, w, h) in regions:\n",
    "            cv2.rectangle(image, (x, y),\n",
    "                        (x + w, y + h),\n",
    "                        (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "\n",
    "# Start a while loop\n",
    "\n",
    "\n",
    "    # Reading the video from the\n",
    "    # webcam in image frames\n",
    "#     _, imageFrame = webcam.read()\n",
    "\n",
    "    # Convert the imageFrame in\n",
    "    # BGR(RGB color space) to\n",
    "    # HSV(hue-saturation-value)\n",
    "    # color space\n",
    "    hsvFrame = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Set range for red color and\n",
    "#                 # define mask\n",
    "#                 red_lower = np.array([136, 87, 111], np.uint8)\n",
    "#                 red_upper = np.array([180, 255, 255], np.uint8)\n",
    "#                 red_mask = cv2.inRange(hsvFrame, red_lower, red_upper)\n",
    "\n",
    "\n",
    "#     green_lower = np.array([25, 52, 72], np.uint8)\n",
    "#     green_upper = np.array([102, 255, 255], np.uint8)\n",
    "#     green_mask = cv2.inRange(hsvFrame, green_lower, green_upper)\n",
    "\n",
    "    # Set range for blue color and\n",
    "#                 # define mask\n",
    "    blue_lower = np.array([94, 80, 2], np.uint8)\n",
    "    blue_upper = np.array([120, 255, 255], np.uint8)\n",
    "    blue_mask = cv2.inRange(hsvFrame, blue_lower, blue_upper)\n",
    "\n",
    "    # Morphological Transform, Dilation\n",
    "    # for each color and bitwise_and operator\n",
    "    # between imageFrame and mask determines\n",
    "    # to detect only that particular color\n",
    "    kernal = np.ones((5, 5), \"uint8\")\n",
    "\n",
    "#                 # For red color\n",
    "#                 red_mask = cv2.dilate(red_mask, kernal)\n",
    "#                 res_red = cv2.bitwise_and(img, img,\n",
    "#                                         mask = red_mask)\n",
    "\n",
    "#     # For green color\n",
    "#     green_mask = cv2.dilate(green_mask, kernal)\n",
    "#     res_green = cv2.bitwise_and(image, image,\n",
    "#                                 mask = green_mask)\n",
    "\n",
    "#                 # For blue color\n",
    "    blue_mask = cv2.dilate(blue_mask, kernal)\n",
    "    res_blue = cv2.bitwise_and(img, img,\n",
    "                                        mask = blue_mask)\n",
    "\n",
    "#                 # Creating contour to track red color\n",
    "#                 contours, hierarchy = cv2.findContours(red_mask,\n",
    "#                                                     cv2.RETR_TREE,\n",
    "#                                                     cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#                 for pic, contour in enumerate(contours):\n",
    "#                     area = cv2.contourArea(contour)\n",
    "#                     if(area > 300):\n",
    "#                         x, y, w, h = cv2.boundingRect(contour)\n",
    "#                         img = cv2.rectangle(img, (x, y),\n",
    "#                                                 (x + w, y + h),\n",
    "#                                                 (0, 0, 255), 2)\n",
    "\n",
    "#                         cv2.putText(img, \"Red Colour\", (x, y),\n",
    "#                                     cv2.FONT_HERSHEY_SIMPLEX, 1.0,\n",
    "#                                     (0, 0, 255))\t\n",
    "\n",
    "    # Creating contour to track green color\n",
    "    contours, hierarchy = cv2.findContours(green_mask,\n",
    "                                        cv2.RETR_TREE,\n",
    "                                        cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for pic, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "\n",
    "        if(area > 300):\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            img = cv2.rectangle(image, (x, y),\n",
    "                                    (x + w, y + h),\n",
    "                                    (0, 255, 0), 2)\n",
    "\n",
    "            (regions, _) = hog.detectMultiScale(image,\n",
    "                            winStride=(16, 16),\n",
    "                            padding=(8, 8),\n",
    "                            scale=1.02)\n",
    "\n",
    "        # Drawing the regions in the\n",
    "        # Image\n",
    "            for (x, y, w, h) in regions:\n",
    "                cv2.rectangle(image, (x, y),\n",
    "                            (x + w, y + h),\n",
    "                            (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            cv2.putText(img, \"blue Colour\", (x, y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1.0, (0, 255, 0))\n",
    "\n",
    "#                 # Creating contour to track blue color\n",
    "#                 contours, hierarchy = cv2.findContours(blue_mask,\n",
    "#                                                     cv2.RETR_TREE,\n",
    "#                                                     cv2.CHAIN_APPROX_SIMPLE)\n",
    "#                 for pic, contour in enumerate(contours):\n",
    "#                     area = cv2.contourArea(contour)\n",
    "#                     if(area > 300):\n",
    "#                         x, y, w, h = cv2.boundingRect(contour)\n",
    "#                         img = cv2.rectangle(img, (x, y),\n",
    "#                                                 (x + w, y + h),\n",
    "#                                                 (255, 0, 0), 2)\n",
    "\n",
    "#                         cv2.putText(img, \"Blue Colour\", (x, y),\n",
    "#                                     cv2.FONT_HERSHEY_SIMPLEX,\n",
    "#                                     1.0, (255, 0, 0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    cv2.imshow('img', image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break    \n",
    "# Release the VideoCapture object\n",
    "cap.release()\n",
    "# video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f1c306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "\n",
    "\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "face_cascade=cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "            # face_cascade=cv2.CascadeClassifier(cv2.data.haarcascades +\"haarcascade_upperbody.xml\")\n",
    "\n",
    "            # To capture video from webcam. \n",
    "cap = cv2.VideoCapture(0)\n",
    "# To use a video file as input \n",
    "# cap = cv2.VideoCapture('filename.mp4')\n",
    "\n",
    "while True:\n",
    "    # Read the frame\n",
    "    ret, img = cap.read()\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#                 Detect the faces\n",
    "#                 faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "#                 # Draw the rectangle around each face\n",
    "#                 for (x, y, w, h) in faces:\n",
    "#                     cv2.rectangle(img, (x, y), (x+w, y+h), (255, 255, 255), 2)\n",
    "#                 # Display\n",
    "#                 cv2.imshow('img', img)\n",
    "# #                 Stop if escape key is pressed\n",
    "#                 k = cv2.waitKey(30) & 0xff\n",
    "#                 if k==27:\n",
    "#                     break\n",
    "\n",
    "\n",
    "# Start a while loop\n",
    "\n",
    "\n",
    "    # Reading the video from the\n",
    "    # webcam in image frames\n",
    "#     _, imageFrame = webcam.read()\n",
    "\n",
    "    # Convert the imageFrame in\n",
    "    # BGR(RGB color space) to\n",
    "    # HSV(hue-saturation-value)\n",
    "     # color space\n",
    "    hsvFrame = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Set range for red color and\n",
    "#                 # define mask\n",
    "#                 red_lower = np.array([136, 87, 111], np.uint8)\n",
    "#                 red_upper = np.array([180, 255, 255], np.uint8)\n",
    "#                 red_mask = cv2.inRange(hsvFrame, red_lower, red_upper)\n",
    "\n",
    "\n",
    "#                 green_lower = np.array([25, 52, 72], np.uint8)\n",
    "#                 green_upper = np.array([102, 255, 255], np.uint8)\n",
    "#                 green_mask = cv2.inRange(hsvFrame, green_lower, green_upper)\n",
    "\n",
    "    # Set range for blue color and\n",
    "    # define mask\n",
    "    blue_lower = np.array([94, 80, 2], np.uint8)\n",
    "    blue_upper = np.array([120, 255, 255], np.uint8)\n",
    "    blue_mask = cv2.inRange(hsvFrame, blue_lower, blue_upper)\n",
    "\n",
    "    # Morphological Transform, Dilation\n",
    "    # for each color and bitwise_and operator\n",
    "    # between imageFrame and mask determines\n",
    "    # to detect only that particular color\n",
    "    kernal = np.ones((5, 5), \"uint8\")\n",
    "\n",
    "#                 # For red color\n",
    "#                 red_mask = cv2.dilate(red_mask, kernal)\n",
    "#                 res_red = cv2.bitwise_and(img, img,\n",
    "#                                         mask = red_mask)\n",
    "\n",
    "#                 # For green color\n",
    "#                 green_mask = cv2.dilate(green_mask, kernal)\n",
    "#                 res_green = cv2.bitwise_and(img, img,\n",
    "#                                             mask = green_mask)\n",
    "\n",
    "    # For blue color\n",
    "    blue_mask = cv2.dilate(blue_mask, kernal)\n",
    "    res_blue = cv2.bitwise_and(img, img,\n",
    "                            mask = blue_mask)\n",
    "\n",
    "#                 # Creating contour to track red color\n",
    "#                 contours, hierarchy = cv2.findContours(red_mask,\n",
    "#                                                     cv2.RETR_TREE,\n",
    "#                                                     cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#                 for pic, contour in enumerate(contours):\n",
    "#                     area = cv2.contourArea(contour)\n",
    "#                     if(area > 300):\n",
    "#                         x, y, w, h = cv2.boundingRect(contour)\n",
    "#                         img = cv2.rectangle(img, (x, y),\n",
    "#                                                 (x + w, y + h),\n",
    "#                                                 (0, 0, 255), 2)\n",
    "\n",
    "#                         cv2.putText(img, \"Red Colour\", (x, y),\n",
    "#                                     cv2.FONT_HERSHEY_SIMPLEX, 1.0,\n",
    "#                                     (0, 0, 255))\t\n",
    "\n",
    "#                 # Creating contour to track green color\n",
    "#                 contours, hierarchy = cv2.findContours(green_mask,\n",
    "#                                                     cv2.RETR_TREE,\n",
    "#                                                     cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#                 for pic, contour in enumerate(contours):\n",
    "#                     area = cv2.contourArea(contour)\n",
    "#                     if(area > 300):\n",
    "#                         x, y, w, h = cv2.boundingRect(contour)\n",
    "#                         img = cv2.rectangle(img, (x, y),\n",
    "#                                                 (x + w, y + h),\n",
    "#                                                 (0, 255, 0), 2)\n",
    "\n",
    "#                         cv2.putText(img, \"Green Colour\", (x, y),\n",
    "#                                     cv2.FONT_HERSHEY_SIMPLEX,\n",
    "#                                     1.0, (0, 255, 0))\n",
    "\n",
    "    # Creating contour to track blue color\n",
    "    contours, hierarchy = cv2.findContours(blue_mask,\n",
    "                                        cv2.RETR_TREE,\n",
    "                                        cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for pic, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "#         if ret:\n",
    "        image = imutils.resize(img,width=min(400, img.shape[1]))\n",
    "\n",
    "        # Detecting all the regions\n",
    "        # in the Image that has a\n",
    "        # pedestrians inside it\n",
    "        (regions, _) = hog.detectMultiScale(image,\n",
    "                                            winStride=(16, 16),\n",
    "                                            padding=(8, 8),\n",
    "                                            scale=1.02)\n",
    "\n",
    "        # Drawing the regions in the\n",
    "        # Image\n",
    "        for (x, y, w, h) in regions:\n",
    "            cv2.rectangle(image, (x, y),\n",
    "                        (x + w, y + h),\n",
    "                        (0, 0, 255), 2)\n",
    "\n",
    "        # Draw the rectangle around each face\n",
    "        if(area > 500):\n",
    "            for (x, y, w, h) in faces:\n",
    "                cv2.rectangle(img, (x, y), (x+w, y+h), (255, 255, 255), 2)\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            img = cv2.rectangle(img, (x, y),\n",
    "                                    (x + w, y + h),\n",
    "                                    (0, 255, 0), 2)\n",
    "\n",
    "#                         faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "#                 # Draw the rectangle around each face\n",
    "#                         for (x, y, w, h) in faces:\n",
    "#                             cv2.rectangle(img, (x, y), (x+w, y+h), (255, 255, 255), 2)\n",
    "\n",
    "            cv2.putText(img, \"Blue Colour\", (x, y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1.0, (255, 0, 0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    cv2.imshow('img', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break    \n",
    "# Release the VideoCapture object\n",
    "cap.release()\n",
    "# video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7a1135a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_22820/497375383.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\ASUS\\AppData\\Local\\Temp/ipykernel_22820/497375383.py\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    file = open(file_name, &quot;r&quot;)\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "def read_article(file_name):\n",
    "    file = open(file_name, &quot;r&quot;)\n",
    "    filedata = file.readlines()\n",
    "    article = filedata[0].split(&quot;. &quot;)\n",
    "    sentences = [] for sentence in article:\n",
    "    print(sentence)\n",
    "    sentences.append(sentence.replace(&quot;[^a-zA-Z]&quot;, &quot; &quot;).split(&quot;\n",
    "    &quot;))\n",
    "    sentences.pop()\n",
    "return sentences\n",
    "\n",
    "\n",
    "def build_similarity_matrix(sentences, stop_words):\n",
    "# Create an empty similarity matrix\n",
    "    similarity_matrix = np.zeros((len(sentences),\n",
    "    len(sentences)))\n",
    "    for idx1 in range(len(sentences)):\n",
    "    for idx2 in range(len(sentences)):\n",
    "    if idx1 == idx2: #ignore if both are same sentences\n",
    "    continue\n",
    "    similarity_matrix[idx1][idx2] =\n",
    "    sentence_similarity(sentences[idx1], sentences[idx2],\n",
    "    stop_words)return similarity_matrix\n",
    "\n",
    "\n",
    "def generate_summary(file_name, top_n=5):\n",
    "    stop_words = stopwords.words(&#39;english&#39;)\n",
    "    summarize_text = [] # Step 1 - Read text and tokenize\n",
    "    sentences = read_article(file_name) # Step 2 - Generate\n",
    "    Similary Martix across sentences\n",
    "    sentence_similarity_martix =\n",
    "    build_similarity_matrix(sentences, stop_words) # Step 3 -\n",
    "    Rank sentences in similarity martix\n",
    "    sentence_similarity_graph =\n",
    "    nx.from_numpy_array(sentence_similarity_martix)\n",
    "    scores = nx.pagerank(sentence_similarity_graph) # Step 4\n",
    "    - Sort the rank and pick top sentences\n",
    "    ranked_sentence = sorted(((scores[i],s) for i,s in\n",
    "    enumerate(sentences)), reverse=True)\n",
    "    print(&quot;Indexes of top ranked_sentence order are &quot;,\n",
    "    ranked_sentence)for i in range(top_n):\n",
    "    summarize_text.append(&quot; &quot;.join(ranked_sentence[i][1]))\n",
    "    # Step 5 - Offcourse, output the summarize texr\n",
    "    print(&quot;Summarize Text: \\n&quot;, &quot;. &quot;.join(summarize_text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6e1b57",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\matrix.cpp:809: error: (-215:Assertion failed) 0 <= roi.x && 0 <= roi.width && roi.x + roi.width <= m.cols && 0 <= roi.y && 0 <= roi.height && roi.y + roi.height <= m.rows in function 'cv::Mat::Mat'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7844/2733605891.py\u001b[0m in \u001b[0;36mdraw_bounding_box\u001b[1;34m(click, x, y, flag_param, parameters)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mbounding_box\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_pt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx_pt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my_pt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mgrabcut_algorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbounding_box\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7844/2733605891.py\u001b[0m in \u001b[0;36mgrabcut_algorithm\u001b[1;34m(original_image, bounding_box)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mforeground_mdl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m65\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     cv2.grabCut(original_image, segment, bounding_box, background_mdl, foreground_mdl, 5,\n\u001b[0m\u001b[0;32m     42\u001b[0m     cv2.GC_INIT_WITH_RECT)\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\matrix.cpp:809: error: (-215:Assertion failed) 0 <= roi.x && 0 <= roi.width && roi.x + roi.width <= m.cols && 0 <= roi.y && 0 <= roi.height && roi.y + roi.height <= m.rows in function 'cv::Mat::Mat'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pic = cv2.imread('DJI_0431.JPG')\n",
    "plt.imshow(pic)\n",
    "\n",
    "\n",
    "def draw_bounding_box(click, x, y, flag_param, parameters):\n",
    "    global x_pt, y_pt, drawing, top_left_point, bottom_right_point, original_image  \n",
    "    \n",
    "    if click == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        x_pt, y_pt = x, y   \n",
    "\n",
    "    elif click == cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing:\n",
    "            top_left_point, bottom_right_point = (x_pt,y_pt), (x,y)\n",
    "            image[y_pt:y, x_pt:x] = 255 - original_image[y_pt:y, x_pt:x]\n",
    "            cv2.rectangle(image, top_left_point, bottom_right_point, (0,255,0), 2)\n",
    "    \n",
    "    elif click == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        top_left_point, bottom_right_point = (x_pt,y_pt), (x,y)\n",
    "        image[y_pt:y, x_pt:x] = 255 - image[y_pt:y, x_pt:x]\n",
    "        cv2.rectangle(image, top_left_point, bottom_right_point, (0,255,0), 2)\n",
    "        bounding_box = (x_pt, y_pt, x-x_pt, y-y_pt)\n",
    "        \n",
    "        grabcut_algorithm(original_image, bounding_box)\n",
    "        \n",
    "        \n",
    "def grabcut_algorithm(original_image, bounding_box):\n",
    "    \n",
    "    segment = np.zeros(original_image.shape[:2],np.uint8)\n",
    "    \n",
    "    x,y,width,height = bounding_box\n",
    "    segment[y:y+height, x:x+width] = 1\n",
    "\n",
    "    background_mdl = np.zeros((1,65), np.float64)\n",
    "    foreground_mdl = np.zeros((1,65), np.float64)\n",
    "    \n",
    "    cv2.grabCut(original_image, segment, bounding_box, background_mdl, foreground_mdl, 5,\n",
    "    cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "    new_mask = np.where((segment==2)|(segment==0),0,1).astype('uint8')\n",
    "\n",
    "    original_image = original_image*new_mask[:,:,np.newaxis]\n",
    "\n",
    "    cv2.imshow('Result', original_image)\n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__=='__main__':\n",
    "    drawing = False\n",
    "    top_left_point, bottom_right_point = (-1,-1), (-1,-1)\n",
    "\n",
    "    original_image = cv2.imread(\"DJI_0431.JPG\")\n",
    "    original_image = cv2.resize( original_image ,(500,500))\n",
    "    image = original_image.copy()\n",
    "    cv2.namedWindow('Frame')\n",
    "    cv2.setMouseCallback('Frame', draw_bounding_box)\n",
    "\n",
    "    while True:\n",
    "        cv2.imshow('Frame', image)\n",
    "        c = cv2.waitKey(1)\n",
    "        if c == 27:\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196dbf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "labelsPath = os.path.sep.join([args[\"mask_rcnn\"],\n",
    "    \"object_detection_classes_coco.txt\"])\n",
    "LABELS = open(labelsPath).read().strip().split(\"\\n\")\n",
    "# derive the paths to the Mask R-CNN weights and model configuration\n",
    "weightsPath = os.path.sep.join([args[\"mask_rcnn\"],\n",
    "    \"frozen_inference_graph.pb\"])\n",
    "configPath = os.path.sep.join([args[\"mask_rcnn\"],\n",
    "    \"mask_rcnn_inception_v2_coco_2018_01_28.pbtxt\"])\n",
    "# load our Mask R-CNN trained on the COCO dataset (90 classes)\n",
    "# from disk\n",
    "print(\"[INFO] loading Mask R-CNN from disk...\")\n",
    "net = cv2.dnn.readNetFromTensorflow(weightsPath, configPath)\n",
    "\n",
    "\n",
    "K = (args[\"kernel\"], args[\"kernel\"])\n",
    "privacy = False\n",
    "# initialize the video stream, then allow the camera sensor to warm up\n",
    "print(\"[INFO] starting video stream...\")\n",
    "vs = VideoStream(src=0).start()\n",
    "time.sleep(2.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
