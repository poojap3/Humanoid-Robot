{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5fa2382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT ALL REQUIERED LIBRAIES\n",
    "\n",
    "\n",
    "import subprocess\n",
    "import wolframalpha\n",
    "import pyttsx3\n",
    "import tkinter\n",
    "import json\n",
    "import random\n",
    "import operator\n",
    "import speech_recognition as sr\n",
    "import datetime\n",
    "import wikipedia\n",
    "import webbrowser\n",
    "import os\n",
    "import winshell\n",
    "import pyjokes\n",
    "import feedparser\n",
    "import smtplib\n",
    "import ctypes\n",
    "import time\n",
    "import requests\n",
    "import shutil\n",
    "from twilio.rest import Client\n",
    "from clint.textui import progress\n",
    "from ecapture import ecapture as ec\n",
    "from bs4 import BeautifulSoup\n",
    "import win32com.client as wincl\n",
    "from urllib.request import urlopen\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c050a0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SETUP TO TAKE AUDIO INPUT\n",
    "\n",
    "engine = pyttsx3.init('sapi5')\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[1].id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83335658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION TO TAKE AUDIO INPUT\n",
    "\n",
    "def speak(audio):\n",
    "    engine.say(audio)\n",
    "    engine.runAndWait()\n",
    "    \n",
    "    \n",
    "#FUNCTION TO WISH ACCORDING TO TIME \n",
    "\n",
    "def wishMe():\n",
    "    hour = int(datetime.datetime.now().hour)\n",
    "    if hour>= 0 and hour<12:\n",
    "        speak(\"Good Morning\")\n",
    "\n",
    "    elif hour>= 12 and hour<18:\n",
    "        speak(\"Good Afternoon\")\n",
    "\n",
    "    else:\n",
    "        speak(\"Good Evening\")\n",
    "\n",
    "    assname =(\"robo\")\n",
    "    speak(\"I am your Assistant\")\n",
    "    speak(assname)\n",
    "\n",
    "\n",
    "#FUNTION TO ASK FOR COMMAND\n",
    "\n",
    "def username():\n",
    "\n",
    "    speak(\"How can i Help you\")\n",
    "    \n",
    "#FUNTION TO GET TO INPUT AUDIO AND RECOGNIZE THE COMMAND     \n",
    "\n",
    "def takeCommand():\n",
    "\n",
    "    r = sr.Recognizer()\n",
    "\n",
    "    with sr.Microphone() as source:\n",
    "\n",
    "        print(\"Listening...\")\n",
    "        r.pause_threshold = 1\n",
    "        audio = r.listen(source)\n",
    "\n",
    "    try:\n",
    "        print(\"Recognizing...\")\n",
    "        query = r.recognize_google(audio, language ='en-in')\n",
    "        print(f\"User said: {query}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Unable to Recognize your voice.\")\n",
    "        return \"None\"\n",
    "\n",
    "    return query\n",
    "\n",
    "# def sendEmail(to, content):\n",
    "#     server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "#     server.ehlo()\n",
    "#     server.starttls()\n",
    "\n",
    "#     # Enable low security in gmail\n",
    "#     server.login('your email id', 'your email password')\n",
    "#     server.sendmail('your email id', to, content)\n",
    "#     server.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a790d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Recognizing...\n",
      "User said: this is it that you\n",
      "\n",
      "Listening...\n",
      "Recognizing...\n",
      "\n",
      "Unable to Recognize your voice.\n",
      "Listening...\n",
      "Recognizing...\n",
      "\n",
      "Unable to Recognize your voice.\n",
      "Listening...\n",
      "Recognizing...\n",
      "User said: thread\n",
      "\n",
      "Listening...\n",
      "Recognizing...\n",
      "User said: read read\n",
      "\n",
      "Listening...\n"
     ]
    }
   ],
   "source": [
    "#CLEAR ALL COMMAND TAKEN BEFORE \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    clear = lambda: os.system('cls')\n",
    "\n",
    "\n",
    "    clear()\n",
    "    wishMe()\n",
    "    username()\n",
    "\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        query = takeCommand().lower()\n",
    "\n",
    "\n",
    "#         if 'wikipedia' in query:\n",
    "#             speak('Searching Wikipedia...')\n",
    "#             query = query.replace(\"wikipedia\", \"\")\n",
    "#             results = wikipedia.summary(query, sentences = 3)\n",
    "#             speak(\"According to Wikipedia\")\n",
    "#             print(results)\n",
    "#             speak(results)\n",
    "\n",
    "#TO CHECK TIME\n",
    "\n",
    "        elif 'the time' in query:\n",
    "            strTime = datetime.datetime.now().strftime(\"% H:% M:% S\")\n",
    "            speak(f\"Sir, the time is {strTime}\")\n",
    "\n",
    "\n",
    "\n",
    "#         elif 'how are you' in query:\n",
    "#             speak(\"I am fine, Thank you\")\n",
    "#             speak(\"How are you\")\n",
    "\n",
    "#         elif 'fine' in query or \"good\" in query:\n",
    "#             speak(\"It's good to know that your fine\")\n",
    "\n",
    "\n",
    "#         elif \"what's your name\" in query or \"What is your name\" in query:\n",
    "#             speak(\"My friends call me\")\n",
    "#             speak(assname)\n",
    "#             print(\"My friends call me\", assname)\n",
    "\n",
    "\n",
    "#TO TERMINATE THE  GIVEN COMMAND\n",
    "        elif 'exit' in query:\n",
    "            speak(\"Thanks for giving me your time\")\n",
    "            exit()\n",
    "\n",
    "\n",
    "\n",
    "#         elif 'joke' in query:\n",
    "#             speak(pyjokes.get_joke())\n",
    "\n",
    "#         elif \"calculate\" in query:\n",
    "\n",
    "#             app_id = \"Wolframalpha api id\"\n",
    "#             client = wolframalpha.Client(app_id)\n",
    "#             indx = query.lower().split().index('calculate')\n",
    "#             query = query.split()[indx + 1:]\n",
    "#             res = client.query(' '.join(query))\n",
    "#             answer = next(res.results).text\n",
    "#             print(\"The answer is \" + answer)\n",
    "#             speak(\"The answer is \" + answer)\n",
    "\n",
    "#         elif 'search' in query or 'play' in query:\n",
    "\n",
    "#             query = query.replace(\"search\", \"\")\n",
    "#             query = query.replace(\"play\", \"\")\n",
    "#             webbrowser.open(query)\n",
    "\n",
    "#         elif 'news' in query:\n",
    "\n",
    "#             try:\n",
    "#                 jsonObj = urlopen('''https://newsapi.org / v1 / articles?source = the-times-of-india&sortBy = top&apiKey =\\\\times of India Api key\\\\''')\n",
    "#                 data = json.load(jsonObj)\n",
    "#                 i = 1\n",
    "\n",
    "#                 speak('here are some top news from the times of india')\n",
    "#                 print('''=============== TIMES OF INDIA ============'''+ '\\n')\n",
    "\n",
    "#                 for item in data['articles']:\n",
    "\n",
    "#                     print(str(i) + '. ' + item['title'] + '\\n')\n",
    "#                     print(item['description'] + '\\n')\n",
    "#                     speak(str(i) + '. ' + item['title'] + '\\n')\n",
    "#                     i += 1\n",
    "#             except Exception as e:\n",
    "\n",
    "#                 print(str(e))\n",
    "\n",
    "\n",
    "#TO INTERRUPT WHILE GIVING WRONG COMMAND\n",
    "        elif \"don't listen\" in query or \"stop listening\" in query:\n",
    "            speak(\"for how much time you want me to stop from listening commands\")\n",
    "            a = int(takeCommand()\n",
    "            time.sleep(a)\n",
    "            print(a)\n",
    "\n",
    "            \n",
    "#TO TRACK             \n",
    "        elif \"start tracking\" in query:\n",
    "\n",
    "\n",
    "\n",
    "            # Initializing the HOG person\n",
    "            # detector\n",
    "\n",
    "            hog = cv2.HOGDescriptor()\n",
    "            hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "            cap = cv2.VideoCapture(0)\n",
    "\n",
    "            while cap.isOpened():\n",
    "                # Reading the video stream\n",
    "                ret, image = cap.read()\n",
    "                if ret:\n",
    "                    image = imutils.resize(image,\n",
    "                                        width=min(400, image.shape[1]))\n",
    "\n",
    "                    # Detecting all the regions\n",
    "                    # in the Image that has a\n",
    "                    # pedestrians inside it\n",
    "                    (regions, _) = hog.detectMultiScale(image,\n",
    "                                                        winStride=(16, 16),\n",
    "                                                        padding=(8, 8),\n",
    "                                                        scale=1.02)\n",
    "\n",
    "                    # Drawing the regions in the\n",
    "                    # Image\n",
    "                    for (x, y, w, h) in regions:\n",
    "                        cv2.rectangle(image, (x, y),\n",
    "                                    (x + w, y + h),\n",
    "                                    (0, 0, 255), 2)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    # Showing the output Image\n",
    "                    result.write(image)\n",
    "\n",
    "                    cv2.imshow(\"Image\", image)\n",
    "                    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                        break\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "                    \n",
    "                    \n",
    "#TO TRACK PERSON IN RED\n",
    "\n",
    "        elif \"track red\" in query:\n",
    "            \n",
    "\n",
    "            hog = cv2.HOGDescriptor()\n",
    "            hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "            cap = cv2.VideoCapture(0)\n",
    "\n",
    "            while cap.isOpened():\n",
    "                # Reading the video stream\n",
    "                ret, image = cap.read()\n",
    "\n",
    "\n",
    "                # Convert the imageFrame in\n",
    "                # BGR(RGB color space) to\n",
    "                # HSV(hue-saturation-value)\n",
    "                # color space\n",
    "                hsvFrame = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "           \n",
    "                             # define mask\n",
    "                red_lower = np.array([136, 87, 111], np.uint8)\n",
    "                red_upper = np.array([180, 255, 255], np.uint8)\n",
    "                red_mask = cv2.inRange(hsvFrame, red_lower, red_upper)\n",
    "\n",
    "                # Morphological Transform, Dilation\n",
    "                # for each color and bitwise_and operator\n",
    "                # between imageFrame and mask determines\n",
    "                # to detect only that particular color\n",
    "                kernal = np.ones((5, 5), \"uint8\")\n",
    "\n",
    "         \n",
    "\n",
    "            #                 # For blue color\n",
    "                red_mask = cv2.dilate(red_mask, kernal)\n",
    "                res_red = cv2.bitwise_and(image, image,\n",
    "                                                    mask = red_mask)\n",
    "\n",
    "           \n",
    "                # Creating contour to track green color\n",
    "                contours, hierarchy = cv2.findContours(red_mask,\n",
    "                                                                cv2.RETR_TREE,\n",
    "                                                                cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "\n",
    "                for pic, contour in enumerate(contours):\n",
    "                    area = cv2.contourArea(contour)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    if(area > 600):\n",
    "                        x, y, w, h = cv2.boundingRect(contour)\n",
    "                        img = cv2.rectangle(image, (x, y),\n",
    "                                                (x + w, y + h),\n",
    "                                                (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "                        (regions, _) = hog.detectMultiScale(img,\n",
    "                                        winStride=(16, 16),\n",
    "                                        padding=(8, 8),\n",
    "                                        scale=1.02)\n",
    "\n",
    "                    # Drawing the regions in the\n",
    "                    # Image\n",
    "                        for (x, y, w, h) in regions:\n",
    "                            cv2.rectangle(image, (x, y),\n",
    "                                        (x + w, y + h),\n",
    "                                        (0, 0, 255), 2)\n",
    "\n",
    "                            if ret:\n",
    "                                image = imutils.resize(image,\n",
    "                                                    width=min(400, image.shape[1]))\n",
    "\n",
    "                                # Detecting all the regions\n",
    "                                # in the Image that has a\n",
    "                                # pedestrians inside it\n",
    "                                (regions, _) = hog.detectMultiScale(image,\n",
    "                                                                    winStride=(16, 16),\n",
    "                                                                    padding=(8, 8),\n",
    "                                                                    scale=1.02)\n",
    "\n",
    "                                # Drawing the regions in the\n",
    "                                # Image\n",
    "                                for (x, y, w, h) in regions:\n",
    "                                    cv2.rectangle(image, (x, y),\n",
    "                                                (x + w, y + h),\n",
    "                                                (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "\n",
    "                        cv2.putText(img, \"red Colour\", (x, y),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                    1.0, (0, 255, 0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                cv2.imshow('img', image)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break    \n",
    "            # Release the VideoCapture object\n",
    "            cap.release()\n",
    "            # video_capture.release()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "#TO TRACK PERSON IN GREEN\n",
    "\n",
    "        elif \"track green\" in query:\n",
    "            \n",
    "\n",
    "            hog = cv2.HOGDescriptor()\n",
    "            hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "            cap = cv2.VideoCapture(0)\n",
    "\n",
    "            while cap.isOpened():\n",
    "                # Reading the video stream\n",
    "                ret, image = cap.read()\n",
    "\n",
    "\n",
    "                # Convert the imageFrame in\n",
    "                # BGR(RGB color space) to\n",
    "                # HSV(hue-saturation-value)\n",
    "                # color space\n",
    "                hsvFrame = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "                \n",
    "                # Set range for blue color and\n",
    "            #                 # define mask\n",
    "                green_lower = np.array([25, 52, 72], np.uint8)\n",
    "                green_upper = np.array([102, 255, 255], np.uint8)\n",
    "                green_mask = cv2.inRange(hsvFrame, green_lower, green_upper)\n",
    "\n",
    "                # Morphological Transform, Dilation\n",
    "                # for each color and bitwise_and operator\n",
    "                # between imageFrame and mask determines\n",
    "                # to detect only that particular color\n",
    "                kernal = np.ones((5, 5), \"uint8\")\n",
    "\n",
    "\n",
    "\n",
    "            #                 # For blue color\n",
    "                green_mask = cv2.dilate(green_mask, kernal)\n",
    "                res_green = cv2.bitwise_and(image, image,mask = green_mask)\n",
    "\n",
    "\n",
    "\n",
    "                # Creating contour to track green color\n",
    "                contours, hierarchy = cv2.findContours(green_mask,\n",
    "                                                                cv2.RETR_TREE,\n",
    "                                                                cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "\n",
    "                for pic, contour in enumerate(contours):\n",
    "                    area = cv2.contourArea(contour)\n",
    "  \n",
    "\n",
    "                    #draw box if area of color is greater than 600px\n",
    "                    if(area > 600):\n",
    "                        x, y, w, h = cv2.boundingRect(contour)\n",
    "                        img = cv2.rectangle(image, (x, y),\n",
    "                                                (x + w, y + h),\n",
    "                                                (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "                        (regions, _) = hog.detectMultiScale(img,\n",
    "                                        winStride=(16, 16),\n",
    "                                        padding=(8, 8),\n",
    "                                        scale=1.02)\n",
    "\n",
    "                    # Drawing the regions in the\n",
    "                    # Image\n",
    "                        for (x, y, w, h) in regions:\n",
    "                            cv2.rectangle(image, (x, y),\n",
    "                                        (x + w, y + h),\n",
    "                                        (0, 0, 255), 2)\n",
    "\n",
    "                            if ret:\n",
    "                                image = imutils.resize(image,\n",
    "                                                    width=min(400, image.shape[1]))\n",
    "\n",
    "                                # Detecting all the regions\n",
    "                                # in the Image that has a\n",
    "                                # pedestrians inside it\n",
    "                                (regions, _) = hog.detectMultiScale(image,\n",
    "                                                                    winStride=(16, 16),\n",
    "                                                                    padding=(8, 8),\n",
    "                                                                    scale=1.02)\n",
    "\n",
    "                                # Drawing the regions in the\n",
    "                                # Image\n",
    "                                for (x, y, w, h) in regions:\n",
    "                                    cv2.rectangle(image, (x, y),\n",
    "                                                (x + w, y + h),\n",
    "                                                (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "\n",
    "                        cv2.putText(img, \"green Colour\", (x, y),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                    1.0, (0, 255, 0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                cv2.imshow('img', image)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break    \n",
    "            # Release the VideoCapture object\n",
    "            cap.release()\n",
    "            # video_capture.release()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "     \n",
    "\n",
    " \n",
    "\n",
    "   \n",
    "#TO TRACK PERSON IN BLUE\n",
    "                    \n",
    "        elif \"track blue\" in query:\n",
    "\n",
    "\n",
    "\n",
    "            hog = cv2.HOGDescriptor()\n",
    "            hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "            cap = cv2.VideoCapture(0)\n",
    "\n",
    "            while cap.isOpened():\n",
    "                # Reading the video stream\n",
    "                ret, image = cap.read()\n",
    " \n",
    "                # Convert the imageFrame in\n",
    "                # BGR(RGB color space) to\n",
    "                # HSV(hue-saturation-value)\n",
    "                # color space\n",
    "                hsvFrame = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "                # Set range for blue color and\n",
    "                            # define mask\n",
    "                blue_lower = np.array([94, 80, 2], np.uint8)\n",
    "                blue_upper = np.array([120, 255, 255], np.uint8)\n",
    "                blue_mask = cv2.inRange(hsvFrame, blue_lower, blue_upper)\n",
    "\n",
    "                # Morphological Transform, Dilation\n",
    "                # for each color and bitwise_and operator\n",
    "                # between imageFrame and mask determines\n",
    "                # to detect only that particular color\n",
    "                kernal = np.ones((5, 5), \"uint8\")\n",
    "\n",
    "            \n",
    "\n",
    "            #                 # For blue color\n",
    "                blue_mask = cv2.dilate(blue_mask, kernal)\n",
    "                res_blue = cv2.bitwise_and(image, image,\n",
    "                                        mask = blue_mask)\n",
    "\n",
    "           \n",
    "                # Creating contour to track green color\n",
    "                contours, hierarchy = cv2.findContours(blue_mask,\n",
    "                                                    cv2.RETR_TREE,\n",
    "                                                    cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "                for pic, contour in enumerate(contours):\n",
    "                    area = cv2.contourArea(contour)\n",
    "           \n",
    "\n",
    "\n",
    "                    if(area > 600):\n",
    "                        x, y, w, h = cv2.boundingRect(contour)\n",
    "                        img = cv2.rectangle(image, (x, y),\n",
    "                                                (x + w, y + h),\n",
    "                                                (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "                        (regions, _) = hog.detectMultiScale(img,\n",
    "                                        winStride=(16, 16),\n",
    "                                        padding=(8, 8),\n",
    "                                        scale=1.02)\n",
    "\n",
    "                    # Drawing the regions in the\n",
    "                    # Image\n",
    "                        for (x, y, w, h) in regions:\n",
    "                            cv2.rectangle(image, (x, y),\n",
    "                                        (x + w, y + h),\n",
    "                                        (0, 0, 255), 2)\n",
    "\n",
    "                            if ret:\n",
    "                                image = imutils.resize(image,\n",
    "                                                    width=min(400, image.shape[1]))\n",
    "\n",
    "                                # Detecting all the regions\n",
    "                                # in the Image that has a\n",
    "                                # pedestrians inside it\n",
    "                                (regions, _) = hog.detectMultiScale(image,\n",
    "                                                                    winStride=(16, 16),\n",
    "                                                                    padding=(8, 8),\n",
    "                                                                    scale=1.02)\n",
    "\n",
    "                                # Drawing the regions in the\n",
    "                                # Image\n",
    "                                for (x, y, w, h) in regions:\n",
    "                                    cv2.rectangle(image, (x, y),\n",
    "                                                (x + w, y + h),\n",
    "                                                (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "\n",
    "                        cv2.putText(img, \"blue Colour\", (x, y),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                    1.0, (0, 255, 0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                cv2.imshow('img', image)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break    \n",
    "            # Release the VideoCapture object\n",
    "            cap.release()\n",
    "            # video_capture.release()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "                    \n",
    "#TO START CAMERA AND DETECT FACE WITH COLOR\n",
    "                    \n",
    "        elif \"camera\" in query or \"start video\" in query:\n",
    "#             ec.capture(0, \"Camera \", \"img.jpg\")\n",
    "            \n",
    "           \n",
    "\n",
    "            # Load the cascade\n",
    "            # face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "            \n",
    "            face_cascade=cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "            # face_cascade=cv2.CascadeClassifier(cv2.data.haarcascades +\"haarcascade_upperbody.xml\")\n",
    "\n",
    "            # To capture video from webcam. \n",
    "            cap = cv2.VideoCapture(0)\n",
    "            # To use a video file as input \n",
    "            # cap = cv2.VideoCapture('filename.mp4')\n",
    "\n",
    "            while True:\n",
    "                # Read the frame\n",
    "                _, img = cap.read()\n",
    "                # Convert to grayscale\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                # Detect the faces\n",
    "                faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "                # Draw the rectangle around each face\n",
    "                for (x, y, w, h) in faces:\n",
    "                    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 255, 255), 2)\n",
    "                # Display\n",
    "                cv2.imshow('img', img)\n",
    "               \n",
    "                # Convert the imageFrame in\n",
    "                # BGR(RGB color space) to\n",
    "                # HSV(hue-saturation-value)\n",
    "                # color space\n",
    "                hsvFrame = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "                # Set range for red color and\n",
    "                # define mask\n",
    "                red_lower = np.array([136, 87, 111], np.uint8)\n",
    "                red_upper = np.array([180, 255, 255], np.uint8)\n",
    "                red_mask = cv2.inRange(hsvFrame, red_lower, red_upper)\n",
    "\n",
    "                \n",
    "                green_lower = np.array([25, 52, 72], np.uint8)\n",
    "                green_upper = np.array([102, 255, 255], np.uint8)\n",
    "                green_mask = cv2.inRange(hsvFrame, green_lower, green_upper)\n",
    "\n",
    "                # Set range for blue color and\n",
    "                # define mask\n",
    "                blue_lower = np.array([94, 80, 2], np.uint8)\n",
    "                blue_upper = np.array([120, 255, 255], np.uint8)\n",
    "                blue_mask = cv2.inRange(hsvFrame, blue_lower, blue_upper)\n",
    "\n",
    "                # Morphological Transform, Dilation\n",
    "                # for each color and bitwise_and operator\n",
    "                # between imageFrame and mask determines\n",
    "                # to detect only that particular color\n",
    "                kernal = np.ones((5, 5), \"uint8\")\n",
    "\n",
    "                # For red color\n",
    "                red_mask = cv2.dilate(red_mask, kernal)\n",
    "                res_red = cv2.bitwise_and(img, img,\n",
    "                                        mask = red_mask)\n",
    "\n",
    "                # For green color\n",
    "                green_mask = cv2.dilate(green_mask, kernal)\n",
    "                res_green = cv2.bitwise_and(img, img,\n",
    "                                            mask = green_mask)\n",
    "\n",
    "                # For blue color\n",
    "                blue_mask = cv2.dilate(blue_mask, kernal)\n",
    "                res_blue = cv2.bitwise_and(img, img,\n",
    "                                        mask = blue_mask)\n",
    "\n",
    "                # Creating contour to track red color\n",
    "                contours, hierarchy = cv2.findContours(red_mask,\n",
    "                                                    cv2.RETR_TREE,\n",
    "                                                    cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "                for pic, contour in enumerate(contours):\n",
    "                    area = cv2.contourArea(contour)\n",
    "                    if(area > 200):\n",
    "                        x, y, w, h = cv2.boundingRect(contour)\n",
    "                        img = cv2.rectangle(img, (x, y),\n",
    "                                                (x + w, y + h),\n",
    "                                                (0, 0, 255), 2)\n",
    "\n",
    "                        cv2.putText(img, \"Red Colour\", (x, y),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1.0,\n",
    "                                    (0, 0, 255))\t\n",
    "\n",
    "                # Creating contour to track green color\n",
    "                contours, hierarchy = cv2.findContours(green_mask,\n",
    "                                                    cv2.RETR_TREE,\n",
    "                                                    cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "                for pic, contour in enumerate(contours):\n",
    "                    area = cv2.contourArea(contour)\n",
    "                    if(area > 300):\n",
    "                        x, y, w, h = cv2.boundingRect(contour)\n",
    "                        img = cv2.rectangle(img, (x, y),\n",
    "                                                (x + w, y + h),\n",
    "                                                (0, 255, 0), 2)\n",
    "\n",
    "                        cv2.putText(img, \"Green Colour\", (x, y),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                    1.0, (0, 255, 0))\n",
    "\n",
    "                # Creating contour to track blue color\n",
    "                contours, hierarchy = cv2.findContours(blue_mask,\n",
    "                                                    cv2.RETR_TREE,\n",
    "                                                    cv2.CHAIN_APPROX_SIMPLE)\n",
    "                for pic, contour in enumerate(contours):\n",
    "                    area = cv2.contourArea(contour)\n",
    "                    if(area > 300):\n",
    "                        x, y, w, h = cv2.boundingRect(contour)\n",
    "                        img = cv2.rectangle(img, (x, y),\n",
    "                                                (x + w, y + h),\n",
    "                                                (255, 0, 0), 2)\n",
    "\n",
    "                        cv2.putText(img, \"Blue Colour\", (x, y),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                    1.0, (255, 0, 0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                cv2.imshow('img', img)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break    \n",
    "            # Release the VideoCapture object\n",
    "            cap.release()\n",
    "            # video_capture.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "            \n",
    "#TO DETECT PERSON IN RED\n",
    "                    \n",
    "                    \n",
    "        elif \"red person\" in query:  \n",
    "\n",
    "\n",
    "\n",
    "            face_cascade=cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "            # face_cascade=cv2.CascadeClassifier(cv2.data.haarcascades +\"haarcascade_upperbody.xml\")\n",
    "\n",
    "            # To capture video from webcam. \n",
    "            cap = cv2.VideoCapture(0)\n",
    "            # To use a video file as input \n",
    "            # cap = cv2.VideoCapture('filename.mp4')\n",
    "\n",
    "            while True:\n",
    "                # Read the frame\n",
    "                _, img = cap.read()\n",
    "                # Convert to grayscale\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                # Detect the faces\n",
    "                faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "                \n",
    "                cv2.imshow('img', img)\n",
    " \n",
    "\n",
    "                # Convert the imageFrame in\n",
    "                # BGR(RGB color space) to\n",
    "                # HSV(hue-saturation-value)\n",
    "                # color space\n",
    "                hsvFrame = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "                # define mask\n",
    "                red_lower = np.array([136, 87, 111], np.uint8)\n",
    "                red_upper = np.array([180, 255, 255], np.uint8)\n",
    "                red_mask = cv2.inRange(hsvFrame, red_lower, red_upper)\n",
    "\n",
    "\n",
    "\n",
    "                # For red color\n",
    "                red_mask = cv2.dilate(red_mask, kernal)\n",
    "                res_red = cv2.bitwise_and(imageFrame, imageFrame,\n",
    "                                        mask = red_mask)\n",
    "\n",
    "\n",
    "                for pic, contour in enumerate(contours):\n",
    "                    area = cv2.contourArea(contour)\n",
    "\n",
    "                    if(area > 300):\n",
    "                        x, y, w, h = cv2.boundingRect(contour)\n",
    "                        img = cv2.rectangle(img, (x, y),\n",
    "                                                (x + w, y + h),\n",
    "                                                (0, 255, 0), 2)\n",
    "                        for (x, y, w, h) in faces:\n",
    "                            cv2.rectangle(img, (x, y), (x+w, y+h), (255, 255, 255), 2)\n",
    "\n",
    "                        cv2.putText(img, \"red Colour\", (x, y),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                    1.0, (0, 255, 0))    \n",
    "\n",
    "\n",
    "                cv2.imshow('img', img)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break    \n",
    "            # Release the VideoCapture object\n",
    "            cap.release()\n",
    "            # video_capture.release()\n",
    "            cv2.destroyAllWindows()            \n",
    "\n",
    "\n",
    "\n",
    "#TO DETECT PERSON IN GREEN \n",
    "                    \n",
    "        elif \"green person\" in query:  \n",
    "\n",
    "\n",
    "\n",
    "            face_cascade=cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "            # face_cascade=cv2.CascadeClassifier(cv2.data.haarcascades +\"haarcascade_upperbody.xml\")\n",
    "\n",
    "            # To capture video from webcam. \n",
    "            cap = cv2.VideoCapture(0)\n",
    "            # To use a video file as input \n",
    "            # cap = cv2.VideoCapture('filename.mp4')\n",
    "\n",
    "            while True:\n",
    "                # Read the frame\n",
    "                _, img = cap.read()\n",
    "                # Convert to grayscale\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                # Detect the faces\n",
    "                faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "               \n",
    "                # Display\n",
    "                cv2.imshow('img', img)\n",
    "                \n",
    "\n",
    "                # Convert the imageFrame in\n",
    "                # BGR(RGB color space) to\n",
    "                # HSV(hue-saturation-value)\n",
    "                # color space\n",
    "                hsvFrame = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "                green_lower = np.array([25, 52, 72], np.uint8)\n",
    "                green_upper = np.array([102, 255, 255], np.uint8)\n",
    "                green_mask = cv2.inRange(hsvFrame, green_lower, green_upper)\n",
    "\n",
    "\n",
    "\n",
    "                green_mask = cv2.dilate(green_mask, kernal)\n",
    "                res_green = cv2.bitwise_and(imageFrame, imageFrame,\n",
    "                                            mask = green_mask)\n",
    "\n",
    "\n",
    "\n",
    "#                \n",
    "\n",
    "                cv2.imshow('img', img)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break    \n",
    "            # Release the VideoCapture object\n",
    "            cap.release()\n",
    "            # video_capture.release()\n",
    "            cv2.destroyAllWindows()            \n",
    "\n",
    "\n",
    "\n",
    "#TO DETECT PERSON IN BLUE                    \n",
    "                    \n",
    "        elif \"blue person\" in query:  \n",
    "\n",
    "\n",
    "\n",
    "            face_cascade=cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "            # face_cascade=cv2.CascadeClassifier(cv2.data.haarcascades +\"haarcascade_upperbody.xml\")\n",
    "\n",
    "            # To capture video from webcam. \n",
    "            cap = cv2.VideoCapture(0)\n",
    "            # To use a video file as input \n",
    "            # cap = cv2.VideoCapture('filename.mp4')\n",
    "\n",
    "            while True:\n",
    "                # Read the frame\n",
    "                _, img = cap.read()\n",
    "                # Convert to grayscale\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                # Detect the faces\n",
    "                faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "                \n",
    "                # Display\n",
    "                cv2.imshow('img', img)\n",
    "               \n",
    "\n",
    "                # Convert the imageFrame in\n",
    "                # BGR(RGB color space) to\n",
    "                # HSV(hue-saturation-value)\n",
    "                # color space\n",
    "                hsvFrame = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "                blue_lower = np.array([94, 80, 2], np.uint8)\n",
    "                blue_upper = np.array([120, 255, 255], np.uint8)\n",
    "                blue_mask = cv2.inRange(hsvFrame, blue_lower, blue_upper)\n",
    "\n",
    "\n",
    "\n",
    "                contours, hierarchy = cv2.findContours(blue_mask,\n",
    "                                                    cv2.RETR_TREE,\n",
    "                                                    cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "                for pic, contour in enumerate(contours):\n",
    "                    area = cv2.contourArea(contour)\n",
    "\n",
    "                    if(area > 300):\n",
    "                        x, y, w, h = cv2.boundingRect(contour)\n",
    "                        img = cv2.rectangle(img, (x, y),\n",
    "                                                (x + w, y + h),\n",
    "                                                (0, 255, 0), 2)\n",
    "                        for (x, y, w, h) in faces:\n",
    "                            cv2.rectangle(img, (x, y), (x+w, y+h), (255, 255, 255), 2)\n",
    "\n",
    "                        cv2.putText(img, \"Blue Colour\", (x, y),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                    1.0, (0, 255, 0))    \n",
    "\n",
    "\n",
    "                cv2.imshow('img', img)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break    \n",
    "            # Release the VideoCapture object\n",
    "            cap.release()\n",
    "            # video_capture.release()\n",
    "            cv2.destroyAllWindows()            \n",
    "\n",
    "                     \n",
    "\n",
    "#         elif \"restart\" in query:\n",
    "#             subprocess.call([\"shutdown\", \"/r\"])\n",
    "\n",
    "#         elif \"hibernate\" in query or \"sleep\" in query:\n",
    "#             speak(\"Hibernating\")\n",
    "#             subprocess.call(\"shutdown / h\")\n",
    "\n",
    "\n",
    "#         elif \"update assistant\" in query:\n",
    "#             speak(\"After downloading file please replace this file with the downloaded one\")\n",
    "#             url = '# url after uploading file'\n",
    "#             r = requests.get(url, stream = True)\n",
    "\n",
    "#             with open(\"Voice.py\", \"wb\") as Pypdf:\n",
    "\n",
    "#                 total_length = int(r.headers.get('content-length'))\n",
    "\n",
    "#                 for ch in progress.bar(r.iter_content(chunk_size = 2391975),\n",
    "#                                     expected_size =(total_length / 1024) + 1):\n",
    "#                     if ch:\n",
    "#                         Pypdf.write(ch)\n",
    "\n",
    "        # NPPR9-FWDCX-D2C8J-H872K-2YT43\n",
    "                    \n",
    "#TO GIVE COMMAND                    \n",
    "        elif \"robo\" in query:\n",
    "\n",
    "            wishMe()\n",
    "            speak(\"what can i help you?\")\n",
    "            speak(assname)\n",
    "\n",
    "#         elif \"weather\" in query:\n",
    "\n",
    "#             # Google Open weather website\n",
    "#             # to get API of Open weather\n",
    "#             api_key = \"Api key\"\n",
    "#             base_url = \"http://api.openweathermap.org / data / 2.5 / weather?\"\n",
    "#             speak(\" City name \")\n",
    "#             print(\"City name : \")\n",
    "#             city_name = takeCommand()\n",
    "#             complete_url = base_url + \"appid =\" + api_key + \"&q =\" + city_name\n",
    "#             response = requests.get(complete_url)\n",
    "#             x = response.json()\n",
    "\n",
    "#             if x[\"code\"] != \"404\":\n",
    "#                 y = x[\"main\"]\n",
    "#                 current_temperature = y[\"temp\"]\n",
    "#                 current_pressure = y[\"pressure\"]\n",
    "#                 current_humidiy = y[\"humidity\"]\n",
    "#                 z = x[\"weather\"]\n",
    "#                 weather_description = z[0][\"description\"]\n",
    "#                 print(\" Temperature (in kelvin unit) = \" +str(current_temperature)+\"\\n atmospheric pressure (in hPa unit) =\"+str(current_pressure) +\"\\n humidity (in percentage) = \" +str(current_humidiy) +\"\\n description = \" +str(weather_description))\n",
    "\n",
    "#             else:\n",
    "#                 speak(\" City Not Found \")\n",
    "\n",
    "#         elif \"wikipedia\" in query:\n",
    "#             webbrowser.open(\"wikipedia.com\")\n",
    "\n",
    "#         elif \"Good Morning\" in query:\n",
    "#             speak(\"A warm\" +query)\n",
    "#             speak(\"How are you Mister\")\n",
    "#             speak(assname)\n",
    "\n",
    "\n",
    "\n",
    "#         elif \"how are you\" in query:\n",
    "#             speak(\"I'm fine, glad you me that\")\n",
    "\n",
    "\n",
    "\n",
    "#         elif \"what is\" in query or \"who is\" in query:\n",
    "\n",
    "           \n",
    "#             client = wolframalpha.Client(\"API_ID\")\n",
    "#             res = client.query(query)\n",
    "\n",
    "#             try:\n",
    "#                 print (next(res.results).text)\n",
    "#                 speak (next(res.results).text)\n",
    "#             except StopIteration:\n",
    "#                 print (\"No results\")\n",
    "\n",
    "#TO STOP THE ASSISTANCE\n",
    "        elif \"good bye\" in query or \"ok bye\" in query or \"stop\" in query:\n",
    "            speak('your personal assistant  is shutting down,Good bye')\n",
    "            print('your personal assistant  is shutting down,Good bye')\n",
    "            break\n",
    "    \n",
    "\n",
    "if \"good bye\" in query or \"ok bye\" in query or \"stop\" in query:\n",
    "            speak('your personal assistant  is shutting down,Good bye')\n",
    "            print('your personal assistant  is shutting down,Good bye')\n",
    "            break            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46d6ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
